<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  

  
  <title>TensorFlow for Deep Learning 1 | Qiuyi&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="I’m learning how to use Google’s TensorFlow framework to create artificial neural networks for deep learning with Python from Udemy. I’m using Jupiter notebook to practice and blog my learning progres">
<meta name="keywords" content="TensorFlow,Deep Learning,Python">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow for Deep Learning 1">
<meta property="og:url" content="https://qiuyiwu.github.io/2018/01/16/Tensorflow-for-Deep-Learning-1/index.html">
<meta property="og:site_name" content="Qiuyi&#39;s Blog">
<meta property="og:description" content="I’m learning how to use Google’s TensorFlow framework to create artificial neural networks for deep learning with Python from Udemy. I’m using Jupiter notebook to practice and blog my learning progres">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF1.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF2.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF3.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF4.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF5.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF6.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF7.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF8.png">
<meta property="og:image" content="https://qiuyiwu.github.io/images/2018/01/TF9.png">
<meta property="og:updated_time" content="2019-01-26T15:18:12.322Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow for Deep Learning 1">
<meta name="twitter:description" content="I’m learning how to use Google’s TensorFlow framework to create artificial neural networks for deep learning with Python from Udemy. I’m using Jupiter notebook to practice and blog my learning progres">
<meta name="twitter:image" content="https://qiuyiwu.github.io/images/2018/01/TF1.png">
  
    <link rel="alternate" href="/atom.xml" title="Qiuyi&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
</html>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Qiuyi&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Researcher✨Qiuyi Wu</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://qiuyiwu.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Tensorflow-for-Deep-Learning-1" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/01/16/Tensorflow-for-Deep-Learning-1/" class="article-date">
  <time datetime="2018-01-16T23:04:34.000Z" itemprop="datePublished">2018-01-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/TensorFlow/">TensorFlow</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TensorFlow for Deep Learning 1
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I’m learning how to use Google’s TensorFlow framework to create artificial neural networks for deep learning with Python from Udemy. I’m using Jupiter notebook to practice and blog my learning progress here.</p>
<p>TensorFlow is an open source software library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them. This architecture allows users to deploy computation to one or more CPUs or GPUs, in a desktop, server, or mobile device with a single API (Application programming interface).</p>
<a id="more"></a>
<h1 id="Install-TensorFlow-Environment"><a href="#Install-TensorFlow-Environment" class="headerlink" title="Install TensorFlow Environment"></a>Install TensorFlow Environment</h1><p><a href="https://www.anaconda.com/download/#macos" target="_blank" rel="noopener">Download Anaconda Distribution</a> for Python 3.6 Version. Tutorial comes in that page.<br>For MacOS: Open Terminal, use <code>cd</code> to the target directory<br>Create the environment file: run <code>conda env create -f tfdl_env.yml</code><br>Activate the file: run <code>source activate tfdeeplearning</code><br>Now you are in the virtual environment of tfdeeplearning<br>If you want to get out of this, run <code>source deactivate</code></p>
<p><strong>Note:</strong> <a href="https://stackoverflow.com/questions/42096280/how-is-anaconda-related-to-python#comment71363474_42096429" target="_blank" rel="noopener">How is Anaconda related to Python?</a><br>Anaconda is a python and R distribution. It aims to provide everything you need (python wise) for data science “out of the box”.<br>It includes:</p>
<ul>
<li>The core python language</li>
<li>100+ python “packages” (libraries)</li>
<li>Spyder (IDE/editor - like pycharm) and Jupyter</li>
<li><code>conda</code>, Anaconda’s own package manager, used for updating Anaconda and packages</li>
</ul>
<p>Also Anaconda is used majorly for the data science. which manipulates large datasets based on statistical methods. ie. Many statistical packages are already available in anaconda libraries(packages) </p>
<p>Vanilla python installed from python.org comew with <a href="https://docs.python.org/3/library/" target="_blank" rel="noopener">standard library</a> is okay, in which case using <a href="https://pypi.python.org/pypi/pip" target="_blank" rel="noopener">pip</a> to install manually (which comes with most python dists and you should have it if you downloaded from python.org).<br>Learn more: <a href="https://www.continuum.io/anaconda-overview" target="_blank" rel="noopener">Anaconda overview</a>; <a href="https://docs.python.org/3/tutorial/" target="_blank" rel="noopener">Python 3 tutorial</a></p>
<h1 id="TensorFlow-Basic-Syntax"><a href="#TensorFlow-Basic-Syntax" class="headerlink" title="TensorFlow Basic Syntax"></a>TensorFlow Basic Syntax</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>
<p>Output: <code>1.3.0</code></p>
<p><strong>Create a tensor ($\approx$ n-dimension array), the basic one (constant)</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hello = tf.constant(<span class="string">'Hello'</span>)</span><br><span class="line">world = tf.constant(<span class="string">'World'</span>)</span><br><span class="line">type (hello)</span><br></pre></td></tr></table></figure></p>
<p>Output: <code>tensorflow.python.framework.ops.Tensor</code></p>
<p><strong>Run this operation inside of a session:</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result = sess.run(hello + world)</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure></p>
<p>Output: <code>b&#39;HelloWorld&#39;</code><br>Note:<br>Use <code>with</code> is to make sure we don’t close the session until we run a block of code then close the session.<br>The <code>b</code> character prefix signifies that <code>HelloWorld</code> is a <a href="https://stackoverflow.com/questions/6224052/what-is-the-difference-between-a-string-and-a-byte-string" target="_blank" rel="noopener">byte string</a>, use <code>result.decode(&#39;utf-8&#39;)</code> to convert byte str to str.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="number">10</span>)</span><br><span class="line">b = tf.constant(<span class="number">20</span>)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    c = sess.run( a + b )</span><br><span class="line">print(c)</span><br></pre></td></tr></table></figure>
<p>Output: <code>30</code></p>
<p><strong>Numpy Operations:</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">const = tf.constant(<span class="number">10</span>)        <span class="comment"># constant operation</span></span><br><span class="line">fill_mat = tf.fill((<span class="number">4</span>,<span class="number">4</span>),<span class="number">10</span>)   <span class="comment"># matrix operation 4x4</span></span><br><span class="line">myzeros = tf.zeros((<span class="number">4</span>,<span class="number">4</span>))      <span class="comment"># 4x4 zeors</span></span><br><span class="line">myones = tf.ones((<span class="number">4</span>,<span class="number">4</span>))        <span class="comment"># 4x4 ones</span></span><br><span class="line">myrandn = tf.random_normal((<span class="number">4</span>,<span class="number">4</span>), mean = <span class="number">0</span>, stddev = <span class="number">1.0</span>)         <span class="comment"># random normal distribution </span></span><br><span class="line">myrandu = tf.random_uniform((<span class="number">4</span>,<span class="number">4</span>), minval = <span class="number">0</span>, maxval = <span class="number">1.0</span>)      <span class="comment"># random uniform distribution </span></span><br><span class="line"></span><br><span class="line">my_ops = [const, fill_mat, myzeros, myones, myrandn, myrandu]</span><br><span class="line"></span><br><span class="line">sess = tf.InteractiveSession()      <span class="comment"># Interactive Session</span></span><br><span class="line"><span class="keyword">for</span> op <span class="keyword">in</span> my_ops:</span><br><span class="line">    print(sess.run(op),<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure></p>
<p>Note:<br><code>Interactive Session</code> is particularly useful for Jupyter Notebook, it allows you to constantly call it through multiple cells.<br>In the Interactive Session, instead of using <code>sess.run(op)</code>, we can use <code>op.eval()</code>, it means “evaluate this operation”, and generates the same result.</p>
<p><strong>Matrix multiplication (common in neural networks)</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">b = tf.constant([[<span class="number">10</span>],[<span class="number">100</span>]])</span><br><span class="line">result = tf.matmul(a,b)</span><br><span class="line">sess.run(result)</span><br></pre></td></tr></table></figure></p>
<span>$$\begin{align*}
    \begin{bmatrix}
        1 &amp; 2 \\
        3 &amp; 4
    \end{bmatrix} \times \begin{bmatrix}
      10 \\ 100
    \end{bmatrix} = \begin{bmatrix}
      210 \\ 430
    \end{bmatrix}
\end{align*}$$</span><!-- Has MathJax -->
<p>Note: <code>sess.run(result)</code> can also use <code>result.eval()</code> instead.</p>
<h1 id="TensorFlow-Graphs"><a href="#TensorFlow-Graphs" class="headerlink" title="TensorFlow Graphs"></a>TensorFlow Graphs</h1><p>Graphs are sets of connected <em>nodes</em>(vertices), and the connections are called <em>edges</em>. In TensorFlow each node is an operation with possible inputs that can supply some outputs. When TenserFlow is started, a default graph is created.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(tf.get_default_graph())</span><br><span class="line">print(tf.Graph())</span><br></pre></td></tr></table></figure>
<p>Output:<br>fixed default graph: <code>&lt;tensorflow.python.framework.ops.Graph object at 0x11f4c92b0&gt;</code><br>Dynamic random graph: <code>&lt;tensorflow.python.framework.ops.Graph object at 0x11f707dd8&gt;</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph_one = tf.Graph()</span><br><span class="line">graph_two = tf.get_default_graph()</span><br><span class="line"><span class="keyword">with</span> graph_one.as_default():</span><br><span class="line">    print(graph_one <span class="keyword">is</span> tf.get_default_graph())</span><br></pre></td></tr></table></figure>
<p>Output: <code>True</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(graph_one <span class="keyword">is</span> tf.get_default_graph())</span><br></pre></td></tr></table></figure></p>
<p>Output: <code>False</code></p>
<h1 id="Variables-and-Placeholders"><a href="#Variables-and-Placeholders" class="headerlink" title="Variables and Placeholders"></a>Variables and Placeholders</h1><p><em>Variables</em> and <em>Placeholders</em> are two main types of tensor objects in a Graph. During the optimization process, TensorFlow tunes the parameters of the model. <em>Variables</em> can hold the values of weights and biases throughout the session. <strong><em>Variables</em> need to be initialized</strong>. <em>Placeholders</em> are initially empty and are used to feed in the actual training examples. However they do need a declared expected data type (tf.float32) with an optiional shape argument.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### Variable ###</span></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">my_tensor = tf.random_uniform((<span class="number">4</span>,<span class="number">4</span>), <span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">my_var = tf.Variable(initial_value = my_tensor)  <span class="comment"># give value to variable </span></span><br><span class="line"><span class="comment"># sess.run(my_var) cannot be directly run here, need initialized first!</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line">sess.run(my_var) <span class="comment"># Now it's the time!</span></span><br></pre></td></tr></table></figure></p>
<p>Output: <code>array([[ 0.27756679,  0.82726526,  0.80544853,  0.43891859],
        [ 0.56279469,  0.57444489,  0.82595968,  0.63165414],
        [ 0.16034544,  0.86095798,  0.74416387,  0.17536163],
        [ 0.44427669,  0.69035304,  0.55842543,  0.00723565]], dtype=float32)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### Placeholder ###</span></span><br><span class="line">ph = tf.placeholder(tf.float32, shape = (<span class="number">4</span>,<span class="number">4</span>)) </span><br><span class="line">ph = tf.placeholder(tf.float32, shape = (<span class="keyword">None</span>,<span class="number">5</span>)) <span class="comment"># can be fed in the actually number of sampes</span></span><br><span class="line">ph = tf.placeholder(tf.float32) <span class="comment"># no shape</span></span><br></pre></td></tr></table></figure>
<h1 id="TensorFlow-Neural-Network"><a href="#TensorFlow-Neural-Network" class="headerlink" title="TensorFlow Neural Network"></a>TensorFlow Neural Network</h1><p>Create a neuron that performs a simple linear fit to some 2-D data. Graph of $wx+b = z$</p>
<ol>
<li>Build a Graph</li>
<li>Initiate the Session</li>
<li>Feed Data In and get Output</li>
<li>Add in the cost function in order to train the network to optimize the parameters<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment">### Build a simple Graph ###</span></span><br><span class="line">np.random.seed(<span class="number">101</span>)</span><br><span class="line">tf.set_random_seed(<span class="number">101</span>)</span><br><span class="line"></span><br><span class="line">rand_a = np.random.uniform(<span class="number">0</span>,<span class="number">100</span>, (<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">rand_b = np.random.uniform(<span class="number">0</span>,<span class="number">100</span>, (<span class="number">5</span>,<span class="number">1</span>))</span><br><span class="line">a = tf.placeholder(tf.float32) <span class="comment"># default shape</span></span><br><span class="line">b = tf.placeholder(tf.float32) <span class="comment"># default shape</span></span><br><span class="line"><span class="comment"># Two ways to do the operation: </span></span><br><span class="line"><span class="comment">#tf.add(a, b)  |  tf.multiply(a, b)  |  tf.matmul(a, b) </span></span><br><span class="line">add_op = a + b</span><br><span class="line">mul_op = a * b</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    add_result = sess.run(add_op, feed_dict = &#123; a:rand_a, b:rand_b&#125;) </span><br><span class="line">    print(add_result, <span class="string">'\n'</span>)</span><br><span class="line">    mul_result = sess.run(mul_op, feed_dict = &#123; a:rand_a, b:rand_b&#125;)</span><br><span class="line">    print(mul_result)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Output:<br>`[[ 151.07165527  156.49855042  102.27921295  116.58396149  167.95948792]<br> [ 135.45622253   82.76316071  141.42784119  124.22093201   71.06043243]<br> [ 113.30171204   93.09214783   76.06819153  136.43911743  154.42727661]<br> [  96.7172699    81.83804321  133.83674622  146.38117981  101.10578918]<br> [ 122.72680664  105.98292542   59.04463196   67.98310089   72.89292145]] </p>
<p>[[ 5134.64404297  5674.25         283.12432861  1705.47070312  6813.83154297]<br> [ 4341.8125      1598.26696777  4652.73388672  3756.8293457    988.9463501 ]<br> [ 3207.8112793   2038.10290527  1052.77416992  4546.98046875  5588.11572266]<br> [ 1707.37902832   614.02526855  4434.98876953  5356.77734375  2029.85546875]<br> [ 3714.09838867  2806.64379883   262.76763916   747.19854736 1013.29199219]]`</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### Build a Neural Network ### </span></span><br><span class="line">n_features = <span class="number">10</span>      <span class="comment"># input layer</span></span><br><span class="line">n_dense_neurons = <span class="number">3</span>  <span class="comment"># hidden layer</span></span><br><span class="line">x = tf.placeholder(tf.float32, (<span class="keyword">None</span>, n_features))</span><br><span class="line">W = tf.Variable(tf.random_normal([n_features, n_dense_neurons]))</span><br><span class="line">b = tf.Variable(tf.ones([n_dense_neurons]))</span><br><span class="line"></span><br><span class="line">xW = tf.matmul(x, W) </span><br><span class="line">z = tf.add(xW, b)</span><br><span class="line"><span class="comment"># a = tf.nn.relu | tf.tahn</span></span><br><span class="line">a = tf.sigmoid(z)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)        <span class="comment"># DON'T FORGET!</span></span><br><span class="line">    layer_out = sess.run(a, feed_dict = &#123; x: np.random.random([<span class="number">1</span>,n_features])&#125;)</span><br><span class="line">print(layer_out)</span><br></pre></td></tr></table></figure>
<p>Output: <code>[[ 0.81314439  0.98195159  0.73793817]]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### Simple Regression Example ###</span></span><br><span class="line">x_data = np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>) + np.random.uniform(<span class="number">-1.5</span>,<span class="number">1.5</span>,<span class="number">10</span>)  <span class="comment"># with noise</span></span><br><span class="line">y_label = np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>) + np.random.uniform(<span class="number">-1.5</span>,<span class="number">1.5</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline     </span><br><span class="line"><span class="comment"># %matplotlib inline    just for Jupyter notebook   </span></span><br><span class="line">plt.plot(x_data, y_label, <span class="string">'*'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/01/TF1.png" alt="Sample Image Added via Markdown"><br>Now I want the neural network to solve $ y = mx + b$ with 10 training steps:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create two random variables</span></span><br><span class="line">m = tf.Variable(<span class="number">0.44</span>)</span><br><span class="line">b = tf.Variable(<span class="number">0.87</span>)</span><br><span class="line"></span><br><span class="line">error = <span class="number">0</span>  <span class="comment"># create an error starting from 0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> zip(x_data, y_label):   <span class="comment"># zip makes a list of x,y</span></span><br><span class="line">    y_hat = m * x + b</span><br><span class="line">    error += (y - y_hat) ** <span class="number">2</span>       <span class="comment"># cost function</span></span><br><span class="line"></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate = <span class="number">0.001</span>)</span><br><span class="line">train = optimizer.minimize(error)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    training_steps = <span class="number">10</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(training_steps):</span><br><span class="line">        sess.run(train)</span><br><span class="line">    final_slope, final_intercept = sess.run([m,b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test </span></span><br><span class="line">x_test = np.linspace(<span class="number">-1</span>,<span class="number">11</span>,<span class="number">10</span>)</span><br><span class="line">y_pred = final_slope * x_test + final_intercept </span><br><span class="line"></span><br><span class="line">plt.plot(x_test, y_pred, <span class="string">'r'</span>)</span><br><span class="line">plt.plot(x_test, y_label,<span class="string">'*'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/2018/01/TF2.png" alt="Sample Image Added via Markdown"></p>
<h1 id="TensorFlow-Regression"><a href="#TensorFlow-Regression" class="headerlink" title="TensorFlow Regression"></a>TensorFlow Regression</h1><p>Regression example with huge dataset:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">0.0</span>,<span class="number">10.0</span>,<span class="number">1000000</span>)  <span class="comment"># huge dataset</span></span><br><span class="line">noise = np.random.randn(len(x_data))    <span class="comment"># add noise</span></span><br><span class="line"><span class="comment"># y = mx + b | b = 5, m = 0.5</span></span><br><span class="line">y_true = (<span class="number">0.5</span> * x_data) + <span class="number">5</span> + noise</span><br><span class="line"></span><br><span class="line">x_df = pd.DataFrame(data = x_data, columns = [<span class="string">'X Data'</span>])</span><br><span class="line">y_df = pd.DataFrame(data = y_true, columns = [<span class="string">'Y'</span>])</span><br><span class="line">my_data = pd.concat([x_df, y_df], axis = <span class="number">1</span>)  <span class="comment"># axis = 1 column concatenate</span></span><br><span class="line">my_data.sample(n = <span class="number">25</span>) <span class="comment"># random 25 samples</span></span><br><span class="line">my_data.sample(n=<span class="number">250</span>).plot(kind = <span class="string">'scatter'</span>, x = <span class="string">'X Data'</span>, y = <span class="string">'Y'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/2018/01/TF3.png" alt="Sample Image Added via Markdown"><br>For real cases, usually the datasets are humongous and we do not use all of them at once. Instead, we use batch method to feed the data batch by batch into the network to save the time. The number of batches depends on the size of the data. Here we feed 1000 batches of data, with each batch has 8 corresponding data points (x data points with corresponding y labels). To make batches useful, we grab 8 random data points via <code>rand_ind = np.random.randint(len(x_data), size = batch_size)</code>, then train the optimizer.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">m = tf.Variable(<span class="number">0.81</span>)</span><br><span class="line">b = tf.Variable(<span class="number">0.17</span>)</span><br><span class="line"></span><br><span class="line">xph = tf.placeholder(tf.float32,[batch_size])</span><br><span class="line">yph = tf.placeholder(tf.float32,[batch_size])</span><br><span class="line"></span><br><span class="line">y_model = m * xph + b    <span class="comment"># the Graph I want to compute</span></span><br><span class="line"><span class="comment"># Loss function</span></span><br><span class="line">error = tf.reduce_sum(tf.square(yph - y_model)) <span class="comment"># tf.reduce_sum: Computes the sum of elements across dimensions of a tensor.</span></span><br><span class="line"><span class="comment"># Optimizer</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate = <span class="number">0.001</span>)     <span class="comment"># This is gradient decent optimizer, there are many other optimizers</span></span><br><span class="line">train = optimizer.minimize(error)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    batches = <span class="number">1000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(batches):</span><br><span class="line">        rand_ind = np.random.randint(len(x_data), size = batch_size)    <span class="comment"># random index</span></span><br><span class="line">        feed = &#123;xph: x_data[rand_ind], yph: y_true[rand_ind]&#125;</span><br><span class="line">        sess.run(train, feed_dict = feed)</span><br><span class="line">    model_m, model_b = sess.run([m, b])</span><br><span class="line"></span><br><span class="line">y_hat = x_data * model_m + model_b</span><br><span class="line">my_data.sample(<span class="number">250</span>).plot(kind = <span class="string">'scatter'</span>, x = <span class="string">'X Data'</span>, y = <span class="string">'Y'</span>)</span><br><span class="line">plt.plot(x_data, y_hat, <span class="string">'r'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/2018/01/TF4.png" alt="Sample Image Added via Markdown"></p>
<h1 id="TensorFlow-Estimator-API"><a href="#TensorFlow-Estimator-API" class="headerlink" title="TensorFlow Estimator API"></a>TensorFlow Estimator API</h1><p>This section is to solve the regression task with TensorFlow estimator API. Wait a minute, what is API?  Technically, API stands for <em>Application Programming Interface</em>, but still, what is that? Basically, it is part of the server, that can be distinctively separated from its environment, that receives requests and sends responses. Here is an excellent article from Petr Gazarov explaining <a href="https://medium.freecodecamp.org/what-is-an-api-in-english-please-b880a3214a82" target="_blank" rel="noopener"><strong>API</strong></a>.<br>There are many other higher levels of APIs (Keras, Layers…). The tf.estimator API has several model types to choose from:</p>
<ul>
<li>tf.estimator.LinearClassifier: Constructs a linear classification model</li>
<li>tf.estimator.LinearRegressor: Constructs a linear regression model</li>
<li>tf.estimator.DNNClassifier: Constructs a neural network classification model</li>
<li>tf.estimator.DNNRegressor: Constructs a neural network regression model</li>
<li>tf.estimator.DNNLinearCombinedRegressor: Constructs a neural network and linear combined regression model</li>
</ul>
<p><br><br>Steps for using the Estimator API:</p>
<ul>
<li>Define a list of feature columns</li>
<li>Create the Estimator Model</li>
<li>Create a Data Input Function</li>
<li>Call train, evaluate, and predict methods on the estimator object</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">feat_cols = [tf.feature_column.numeric_column(<span class="string">'x'</span>, shape = <span class="number">1</span>)]  <span class="comment"># set all feature columns</span></span><br><span class="line">estimator = tf.estimator.LinearRegressor(feature_columns = feat_cols)  <span class="comment"># set estimator</span></span><br><span class="line"><span class="comment"># Split the data</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x_data, y_true, test_size = <span class="number">0.3</span>, random_state = <span class="number">101</span>)</span><br><span class="line"><span class="comment"># Set up Estimator Inputs</span></span><br><span class="line">input_func = tf.estimator.inputs.numpy_input_fn(&#123;<span class="string">'x'</span>: x_train&#125;, y_train, batch_size = <span class="number">8</span>, num_epochs = <span class="keyword">None</span>, shuffle = <span class="keyword">True</span>)     <span class="comment"># we can also use "tf.estimator.inputs.pandas_input_fn"</span></span><br><span class="line">train_input_func = tf.estimator.inputs.numpy_input_fn(&#123;<span class="string">'x'</span>: x_train&#125;, y_train, batch_size = <span class="number">8</span>, num_epochs = <span class="number">1000</span>, shuffle = <span class="keyword">False</span>)     <span class="comment"># change num_epochs and shuffle</span></span><br><span class="line">test_input_func = tf.estimator.inputs.numpy_input_fn(&#123;<span class="string">'x'</span>: x_test&#125;, y_test, batch_size = <span class="number">8</span>, num_epochs = <span class="number">1000</span>, shuffle = <span class="keyword">False</span>)     <span class="comment"># change num_epochs and shuffle, and the dataset</span></span><br><span class="line"><span class="comment"># Train the estimator</span></span><br><span class="line">estimator.train(input_fn = input_func, steps = <span class="number">1000</span>)</span><br><span class="line"><span class="comment"># Evaluation</span></span><br><span class="line">train_matrics = estimator.evaluate(input_fn = train_input_func, steps = <span class="number">1000</span>)</span><br><span class="line">test_matrics = estimator.evaluate(input_fn = test_input_func, steps = <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Training data matrics'</span>)</span><br><span class="line">print(train_matrics)</span><br><span class="line">print(<span class="string">'Test data matrics'</span>)</span><br><span class="line">print(test_matrics)</span><br></pre></td></tr></table></figure>
<p>Output:<br><code>Training data matrics
{&#39;loss&#39;: 8.7310658, &#39;average_loss&#39;: 1.0913832, &#39;global_step&#39;: 1000}
Test data matrics
{&#39;loss&#39;: 8.6690454, &#39;average_loss&#39;: 1.0836307, &#39;global_step&#39;: 1000}</code><br>This is a good way to check if the model is overfitting (very low loss on training data but very high loss on test data). We want the loss of training data and test data are very close to each other.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get predict value</span></span><br><span class="line">brand_new_data = np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">10</span>)</span><br><span class="line">input_fn_predict = tf.estimator.inputs.numpy_input_fn(&#123;<span class="string">'x'</span>: brand_new_data&#125;, shuffle = <span class="keyword">False</span>)</span><br><span class="line">estimator.predict(input_fn = input_fn_predict)</span><br><span class="line">list(estimator.predict(input_fn = input_fn_predict))</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><code>[{&#39;predictions&#39;: array([ 4.43396044], dtype=float32)},
 {&#39;predictions&#39;: array([ 5.06833887], dtype=float32)},
 {&#39;predictions&#39;: array([ 5.7027173], dtype=float32)},
 {&#39;predictions&#39;: array([ 6.33709526], dtype=float32)},
 {&#39;predictions&#39;: array([ 6.97147369], dtype=float32)},
 {&#39;predictions&#39;: array([ 7.60585213], dtype=float32)},
 {&#39;predictions&#39;: array([ 8.24023056], dtype=float32)},
 {&#39;predictions&#39;: array([ 8.87460899], dtype=float32)},
 {&#39;predictions&#39;: array([ 9.50898743], dtype=float32)},
 {&#39;predictions&#39;: array([ 10.14336586], dtype=float32)}]</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># plot the prediction</span></span><br><span class="line">predictions = []</span><br><span class="line"><span class="keyword">for</span> pred <span class="keyword">in</span> estimator.predict(input_fn = input_fn_predict):</span><br><span class="line">    predictions.append(pred[<span class="string">'predictions'</span>])</span><br><span class="line">my_data.sample(<span class="number">250</span>).plot(kind = <span class="string">'scatter'</span>, x = <span class="string">'X Data'</span>, y = <span class="string">'Y'</span>)</span><br><span class="line">plt.plot(brand_new_data, predictions, <span class="string">'r'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/2018/01/TF5.png" alt="Sample Image Added via Markdown"></p>
<h1 id="TensorFlow-Classification"><a href="#TensorFlow-Classification" class="headerlink" title="TensorFlow Classification"></a>TensorFlow Classification</h1><p>Use real dataset “Pima Indians Diabetes Dataset”, including both categorical and continuous features, to use tf.estimator switching models – from linear classifier to dense neural network classifier. </p>
<h2 id="Linear-Classifier"><a href="#Linear-Classifier" class="headerlink" title="Linear Classifier"></a>Linear Classifier</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">diabetes = pd.read_csv(<span class="string">'pima-indians-diabetes.csv'</span>)</span><br><span class="line">diabetes.head()</span><br></pre></td></tr></table></figure>
<p><img src="/images/2018/01/TF6.png" alt="Sample Image Added via Markdown"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">diabetes.columns</span><br></pre></td></tr></table></figure></p>
<p>Output: <code>Index([&#39;Number_pregnant&#39;, &#39;Glucose_concentration&#39;, &#39;Blood_pressure&#39;, &#39;Triceps&#39;,
       &#39;Insulin&#39;, &#39;BMI&#39;, &#39;Pedigree&#39;, &#39;Age&#39;, &#39;Class&#39;, &#39;Group&#39;],
      dtype=&#39;object&#39;)</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># normalize the data except the catagorical part (Age, Class, Group)</span></span><br><span class="line">cols_to_norm = [<span class="string">'Number_pregnant'</span>, <span class="string">'Glucose_concentration'</span>, <span class="string">'Blood_pressure'</span>, <span class="string">'Triceps'</span>,</span><br><span class="line">       <span class="string">'Insulin'</span>, <span class="string">'BMI'</span>, <span class="string">'Pedigree'</span>]</span><br><span class="line">diabetes[cols_to_norm] = diabetes[cols_to_norm].apply(<span class="keyword">lambda</span> x: (x - x.min())/(x.max() - x.min()))</span><br><span class="line">diabetes.head()</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/2018/01/TF7.png" alt="Sample Image Added via Markdown"><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create feature columns</span></span><br><span class="line"><span class="comment"># continuous value</span></span><br><span class="line">num_preg = tf.feature_column.numeric_column(<span class="string">'Number_pregnant'</span>)</span><br><span class="line">plasma_gluc = tf.feature_column.numeric_column(<span class="string">'Glucose_concentration'</span>)</span><br><span class="line">dias_press = tf.feature_column.numeric_column(<span class="string">'Blood_pressure'</span>)</span><br><span class="line">tricep = tf.feature_column.numeric_column(<span class="string">'Triceps'</span>)</span><br><span class="line">insulin = tf.feature_column.numeric_column(<span class="string">'Insulin'</span>)</span><br><span class="line">bmi = tf.feature_column.numeric_column(<span class="string">'BMI'</span>)</span><br><span class="line">diabetes_pedigree = tf.feature_column.numeric_column(<span class="string">'Pedigree'</span>)</span><br><span class="line">age = tf.feature_column.numeric_column(<span class="string">'Age'</span>)</span><br><span class="line"><span class="comment"># catagorical value</span></span><br><span class="line">assigned_group = tf.feature_column.categorical_column_with_vocabulary_list(<span class="string">'Group'</span>, [<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'C'</span>,<span class="string">'D'</span>])     </span><br><span class="line"><span class="comment"># assigned_group = tf.feature_column.categorical_column_with_hash_bucket('Group', hash_bucket_size = 10)  </span></span><br><span class="line"><span class="comment"># For many groups scenario we can use hash_bucket, as long as we set the hash_bucket_size &gt; # of groups</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">diabetes[<span class="string">'Age'</span>].hist(bins = <span class="number">20</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/2018/01/TF8.png" alt="Sample Image Added via Markdown"><br>The distribution of Age from the histgram shows that most of the people are 20s. And instead of treating this variable as a continuous variable, we can bucket these values together, making boundary for each decade or so. <strong>Basically we use bucket system to transform continuous variable into categorial variable.</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">age_bucket = tf.feature_column.bucketized_column(age, boundaries = [<span class="number">20</span>,<span class="number">30</span>,<span class="number">40</span>,<span class="number">50</span>,<span class="number">60</span>,<span class="number">70</span>,<span class="number">80</span>])</span><br><span class="line"><span class="comment"># feature columns</span></span><br><span class="line">feat_cols = [num_preg ,plasma_gluc,dias_press ,tricep ,insulin,bmi,diabetes_pedigree ,assigned_group, age_bucket]</span><br><span class="line"><span class="comment"># train test split</span></span><br><span class="line">x_data = diabetes.drop(<span class="string">'Class'</span>, axis = <span class="number">1</span>)   <span class="comment"># Class column is Y</span></span><br><span class="line">labels = diabetes[<span class="string">'Class'</span>]</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(x_data, labels, test_size = <span class="number">0.3</span>, random_state = <span class="number">101</span>)</span><br></pre></td></tr></table></figure></p>
<p>Create the model!<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Create the model</span></span><br><span class="line">input_func = tf.estimator.inputs.pandas_input_fn(x = X_train, y = y_train, batch_size = <span class="number">10</span>, num_epochs = <span class="number">1000</span>, shuffle = <span class="keyword">True</span>)</span><br><span class="line">model = tf.estimator.LinearClassifier(feature_columns = feat_cols, n_classes = <span class="number">2</span>)</span><br><span class="line">model.train(input_fn = input_func, steps = <span class="number">1000</span>)</span><br><span class="line"><span class="comment">## Evaluate the model</span></span><br><span class="line">eval_input_func = tf.estimator.inputs.pandas_input_fn(x = X_test, y = y_test, batch_size = <span class="number">10</span>, num_epochs = <span class="number">1</span>, shuffle = <span class="keyword">False</span>)</span><br><span class="line">results = model.evaluate(eval_input_func)</span><br><span class="line">results</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><code>{&#39;accuracy&#39;: 0.73160172,
 &#39;accuracy_baseline&#39;: 0.64935064,
 &#39;auc&#39;: 0.79658431,
 &#39;auc_precision_recall&#39;: 0.6441071,
 &#39;average_loss&#39;: 0.52852213,
 &#39;global_step&#39;: 1000,
 &#39;label/mean&#39;: 0.35064936,
 &#39;loss&#39;: 5.0870256,
 &#39;prediction/mean&#39;: 0.35784912}</code><br>The accuracy is 73.16%.</p>
<p> Prediction!<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># No y value in prediction, put new data set in x</span></span><br><span class="line">pred_input_func = tf.estimator.inputs.pandas_input_fn(x = X_test, batch_size = <span class="number">10</span>, num_epochs = <span class="number">1</span>, shuffle = <span class="keyword">False</span>)</span><br><span class="line">predictions = model.predict(pred_input_func)</span><br><span class="line">my_pred = list(predictions)</span><br><span class="line">my_pred</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/2018/01/TF9.png" alt="Sample Image Added via Markdown"></p>
<h2 id="Dense-Neural-Network-Classifier"><a href="#Dense-Neural-Network-Classifier" class="headerlink" title="Dense Neural Network Classifier"></a>Dense Neural Network Classifier</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a three-layer neural network, with 10 neurons in each layer </span></span><br><span class="line">dnn_model = tf.estimator.DNNClassifier(hidden_units = [<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>], feature_columns = feat_cols, n_classes = <span class="number">2</span>)</span><br><span class="line"><span class="comment">### If use the same of the previous step error will show up -- because of the categorial columns, so we need to use embeded group </span></span><br><span class="line">embedded_group_col = tf.feature_column.embedding_column(assigned_group, dimension = <span class="number">4</span>)</span><br><span class="line"><span class="comment">### Reset the feature columns</span></span><br><span class="line">feat_cols = [num_preg ,plasma_gluc,dias_press ,tricep ,insulin,bmi,diabetes_pedigree , embedded_group_col, age_bucket]</span><br><span class="line"><span class="comment">### Now do as the previous -- train the model</span></span><br><span class="line">input_func = tf.estimator.input.pandas_inputs_fn(X_train, y_train, batch_size = <span class="number">10</span>, num_epochs = <span class="number">1000</span>, shuffle = <span class="keyword">True</span>)</span><br><span class="line">dnn_model = tf.estimator.DNNClassifier(hidden_units = [<span class="number">10</span>,<span class="number">10</span>,<span class="number">10</span>], feature_columns = feat_cols, n_classes = <span class="number">2</span>)</span><br><span class="line">dnn_model.train(input_fn = input_func, steps = <span class="number">1000</span>)</span><br><span class="line"><span class="comment"># Evaluate the model</span></span><br><span class="line">eval_input_func = tf.estimator.inputs.pandas_input_fn(x = X_test, y = y_test, batch_size = <span class="number">10</span>, num_epochs = <span class="number">1</span>, shuffle = <span class="keyword">False</span>)</span><br><span class="line">dnn_model.evaluate(eval_input_func)</span><br></pre></td></tr></table></figure>
<p>Output:<br><code>{&#39;accuracy&#39;: 0.75757575,
 &#39;accuracy_baseline&#39;: 0.64935064,
 &#39;auc&#39;: 0.82814813,
 &#39;auc_precision_recall&#39;: 0.67539084,
 &#39;average_loss&#39;: 0.49014509,
 &#39;global_step&#39;: 1000,
 &#39;label/mean&#39;: 0.35064936,
 &#39;loss&#39;: 4.7176466,
 &#39;prediction/mean&#39;: 0.36287409}</code></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://qiuyiwu.github.io/2018/01/16/Tensorflow-for-Deep-Learning-1/" data-id="cjt39xdm1001dxly5wvpe44en" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/01/21/TensorFlow-for-Deep-Learning-2/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          TensorFlow for Deep Learning 2
        
      </div>
    </a>
  
  
    <a href="/2018/01/09/LeetCode1/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">LeetCode in Python3 - Two Sum</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Astrostatistics/">Astrostatistics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Mining/">Data Mining</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/JUJUs/">JUJUs</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/LeetCode/">LeetCode</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Philosophy/">Philosophy</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Research/">Research</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Statistics/">Statistics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/TensorFlow/">TensorFlow</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/API/">API</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Astronomy/">Astronomy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Astrostatistics/">Astrostatistics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Birthday/">Birthday</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chinese-Restaurant/">Chinese Restaurant</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Classification/">Classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DNN/">DNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Fusion/">Data Fusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Mining/">Data Mining</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Disqus/">Disqus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Distance/">Distance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ensemble/">Ensemble</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Firebase/">Firebase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Firestore/">Firestore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gaussian-Process/">Gaussian Process</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Indian-Buffet/">Indian Buffet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KMeans/">KMeans</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KNN/">KNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LeanCloud/">LeanCloud</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Network-Analysis/">Network Analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Network/">Neural Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nietzsche/">Nietzsche</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nonparametric/">Nonparametric</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Philosophy/">Philosophy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/R/">R</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regression/">Regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SVM/">SVM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spatial-Statistics/">Spatial Statistics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Statistics/">Statistics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Topic-Modeling/">Topic Modeling</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TwoSum/">TwoSum</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Valine/">Valine</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vapnik-Chervonenkis/">Vapnik-Chervonenkis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/binary/">binary</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/classification/">classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/comment/">comment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hurrican-tracks/">hurrican tracks</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kNN/">kNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/local-search/">local search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/music/">music</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/storm-surge/">storm surge</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/visitor-counts/">visitor counts</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/尼采/">尼采</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/API/" style="font-size: 10px;">API</a> <a href="/tags/Astronomy/" style="font-size: 10px;">Astronomy</a> <a href="/tags/Astrostatistics/" style="font-size: 10px;">Astrostatistics</a> <a href="/tags/Birthday/" style="font-size: 10px;">Birthday</a> <a href="/tags/CNN/" style="font-size: 15px;">CNN</a> <a href="/tags/Chinese-Restaurant/" style="font-size: 10px;">Chinese Restaurant</a> <a href="/tags/Classification/" style="font-size: 10px;">Classification</a> <a href="/tags/DNN/" style="font-size: 10px;">DNN</a> <a href="/tags/Data-Fusion/" style="font-size: 10px;">Data Fusion</a> <a href="/tags/Data-Mining/" style="font-size: 10px;">Data Mining</a> <a href="/tags/Deep-Learning/" style="font-size: 10px;">Deep Learning</a> <a href="/tags/Disqus/" style="font-size: 10px;">Disqus</a> <a href="/tags/Distance/" style="font-size: 10px;">Distance</a> <a href="/tags/Ensemble/" style="font-size: 10px;">Ensemble</a> <a href="/tags/Firebase/" style="font-size: 10px;">Firebase</a> <a href="/tags/Firestore/" style="font-size: 10px;">Firestore</a> <a href="/tags/Gaussian-Process/" style="font-size: 10px;">Gaussian Process</a> <a href="/tags/Hexo/" style="font-size: 20px;">Hexo</a> <a href="/tags/Indian-Buffet/" style="font-size: 10px;">Indian Buffet</a> <a href="/tags/KMeans/" style="font-size: 10px;">KMeans</a> <a href="/tags/KNN/" style="font-size: 10px;">KNN</a> <a href="/tags/LeanCloud/" style="font-size: 10px;">LeanCloud</a> <a href="/tags/Network-Analysis/" style="font-size: 10px;">Network Analysis</a> <a href="/tags/Neural-Network/" style="font-size: 10px;">Neural Network</a> <a href="/tags/Nietzsche/" style="font-size: 10px;">Nietzsche</a> <a href="/tags/Nonparametric/" style="font-size: 15px;">Nonparametric</a> <a href="/tags/Philosophy/" style="font-size: 10px;">Philosophy</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/R/" style="font-size: 10px;">R</a> <a href="/tags/RNN/" style="font-size: 15px;">RNN</a> <a href="/tags/Regression/" style="font-size: 10px;">Regression</a> <a href="/tags/SVM/" style="font-size: 10px;">SVM</a> <a href="/tags/Spatial-Statistics/" style="font-size: 10px;">Spatial Statistics</a> <a href="/tags/Statistics/" style="font-size: 20px;">Statistics</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/Topic-Modeling/" style="font-size: 15px;">Topic Modeling</a> <a href="/tags/TwoSum/" style="font-size: 10px;">TwoSum</a> <a href="/tags/Valine/" style="font-size: 10px;">Valine</a> <a href="/tags/Vapnik-Chervonenkis/" style="font-size: 10px;">Vapnik-Chervonenkis</a> <a href="/tags/binary/" style="font-size: 10px;">binary</a> <a href="/tags/blog/" style="font-size: 20px;">blog</a> <a href="/tags/classification/" style="font-size: 10px;">classification</a> <a href="/tags/comment/" style="font-size: 10px;">comment</a> <a href="/tags/hurrican-tracks/" style="font-size: 10px;">hurrican tracks</a> <a href="/tags/kNN/" style="font-size: 10px;">kNN</a> <a href="/tags/local-search/" style="font-size: 10px;">local search</a> <a href="/tags/music/" style="font-size: 10px;">music</a> <a href="/tags/storm-surge/" style="font-size: 10px;">storm surge</a> <a href="/tags/visitor-counts/" style="font-size: 10px;">visitor counts</a> <a href="/tags/尼采/" style="font-size: 10px;">尼采</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">June 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/07/BayesianNonparametrics/">Bayesian Nonparametrics Notes</a>
          </li>
        
          <li>
            <a href="/2019/02/19/GaussianProcess/">Why are Gaussian Process Models called Nonparametric?</a>
          </li>
        
          <li>
            <a href="/2019/01/29/Birthday/">Make a Birthday Cake in R</a>
          </li>
        
          <li>
            <a href="/2019/01/27/BlogTheme/">Blog Theme 日神 x 酒神</a>
          </li>
        
          <li>
            <a href="/2019/01/26/Hexo-View/">Add Article Views to Your Hexo Blog</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Qiuyi Wu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>